# 181222-day2-quiz

## 1. 為什麼 Python 程式語言要分成 Python2, Python3 不同的版本，使用上有什麼問題？
因為Python2	存留早期的問題,並且Python2有些功能並不符合Python原始明確、簡單的精神,因此切割出Python3版本
## 2. 完成以下填空：

- 使用者在看瀏覽網站的操作行為，使基於【HTTP】  協定：
- 使用者在瀏覽器上輸入網址…
[使用者/Client side] 發送 【Request】 給 [網站伺服器/ Server side]
- [網站伺服器/ Server side] 回傳 【Response】給 [使用者/Client side]
瀏覽器將內容處理之後顯示給使用者…

## 3. 請問動態網頁爬蟲跟靜態網頁爬蟲主要的差別是什麼？
靜態:網頁上的資料是固定
    動態:網頁上的資料會用 JS進行更新

## 4. 動態網頁爬蟲跟靜態網頁爬蟲的爬蟲策略有什麼差別？
靜態:直接使用 CLASS 方式取的想要的參數(樹狀結構)
    動態:模擬人類開檔方式進行資料取得後再作資料分析
    
## 5. 找一個網站，說明哪些內容是可以透過靜態方式取得？哪些是需要透過動態方式取得？
https://udn.com/news/breaknews/1/2
      動態取得: 蓋板廣告 與 新聞內容
      靜態取得: 一般顯示的 文字或是標題等

## 6. 實作題：利用 Yahoo! 電影，取出本週熱門新片的「中英文名稱」、「上映日期」、「期待度」、「滿意度」，還有「封面照片網址」，並印出。用一個你覺得適合的型態存到一個變數內。
import requests
from selenium import webdriver
from selenium.webdriver.support.ui import Select
from bs4 import BeautifulSoup
url = 'https://movies.yahoo.com.tw/movie_thisweek.html'
#url ='https://www.dcard.tw/f'
r = requests.get(url)
soup = BeautifulSoup(r.text, 'html.parser')
movise = []
imgs = []
#print(soup.find(class_="release_movie_name").find(class_="gabtn").text.replace(' ', '').replace('\n', ''))
for d in soup.find_all(class_="release_info"):
    dictstr= {}
    dictstr['中文名稱']=(d.find(class_="release_info_text").find(class_="release_movie_name").find(class_="gabtn").text.replace(' ', '').replace('\n', ''))
    dictstr['英文名稱']=(d.find(class_="release_info_text").find(class_="en").find(class_="gabtn").text.replace(' ', '').replace('\n', ''))
    dictstr['期待度']=(d.find(class_="release_info_text").find(class_="release_movie_time").text.replace(' ', '').replace('\n', ''))
    dictstr['滿意度']=(d.find(class_="release_info_text").find(class_="leveltext").text.replace(' ', '').replace('\n', ''))
    dictstr['上映時間']=(d.find(class_="release_info_text").find(class_="release_movie_time").text.replace(' ', '').replace('\n', ''))
    movise.append(dictstr)
#    aaa=(d.find(class_="release_info_text").find(class_="release_list")(class_="release_foto"))
#    print(aaa)
import urllib.request    
for ds in soup.find_all(class_="release_foto"):
    #aaa=(ds.find(class_="gabtn").alt)
    #print((ds))
    dictimagestr= {}
    
    dictimagestr['img']=(ds.a.img['src'])
    imgs.append(dictimagestr)
#    print((dictimagestr))    
res = []
for i,j in zip(movise, imgs):
    res.append(dict(list(i.items()) + list(j.items())))
print (res)
# print(res)
#for i, d in enumerate(soup.find_all(class_="release_foto")):
#    dic = {}
#    dic['img'] = d.find("img")['src']
#    urllib.request.urlretrieve(d.find("img")['src'], f'{i}.jpg')
#    imgs.append(dic)
#    (zip(dictstr,dictimagestr))
#    print(dictstr)

## 7. 實作題：利用 104 人力銀行，計算出台中市用「資料」關鍵字可以找到的公司數量有幾個？

方法1:
from selenium import webdriver
from selenium.webdriver.support.ui import Select
from bs4 import BeautifulSoup
import json
headers = {
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6,ja;q=0.5',
    'Connection': 'keep-alive',
    'Cookie': 'luauid=2108599161; _ga=GA1.3.696827056.1517415692; __auc=ed4a51af1614d05f6d120b43bfb; PERSONAL_SORT=B; SYS_SETAB=20140613; _T_MYPOOL_104I=3; 104i_viewJobJobHistory=%5B%224nm6l%22%2C%223i8q6%22%5D; _gid=GA1.3.516194520.1528488749; __asc=bb64e596163e2c7db70da629853; lup=2108599161.5057323988685.4690104285048.1.4507568175053; lunp=4690104285048',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
    'X-Requested-With': 'XMLHttpRequest',
    'Host': 'www.104.com.tw',
    'Referer': 'https://www.104.com.tw/cust/list/index/'
}
count  =0
for p in range(1, 10):
    url = f'https://www.104.com.tw/cust/list/ajax/index?page={p}&keyword=%E8%B3%87%E6%96%99&area=6001008000&order=1&mode=s&jobsource=checkc'
    r = requests.get(url, headers=headers)
    r.encoding = 'utf-8'
    data = json.loads(r.text)['data']['list']      
    for d in data:
        count =count+1
print('總共公司:',count)
方法2:
from selenium import webdriver
from selenium.webdriver.support.ui import Select
from bs4 import BeautifulSoup
import json
headers = {
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-CN;q=0.6,ja;q=0.5',
    'Connection': 'keep-alive',
    'Cookie': 'luauid=2108599161; _ga=GA1.3.696827056.1517415692; __auc=ed4a51af1614d05f6d120b43bfb; PERSONAL_SORT=B; SYS_SETAB=20140613; _T_MYPOOL_104I=3; 104i_viewJobJobHistory=%5B%224nm6l%22%2C%223i8q6%22%5D; _gid=GA1.3.516194520.1528488749; __asc=bb64e596163e2c7db70da629853; lup=2108599161.5057323988685.4690104285048.1.4507568175053; lunp=4690104285048',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',
    'X-Requested-With': 'XMLHttpRequest',
    'Host': 'www.104.com.tw',
    'Referer': 'https://www.104.com.tw/cust/list/index/'
}
tatal =''
count  =0
url = 'https://www.104.com.tw/cust/list/ajax/index?page=1&keyword=%E8%B3%87%E6%96%99&area=6001008000&order=1&mode=s&jobsource=checkc'
r = requests.get(url, headers=headers)
r.encoding = 'utf-8'
data = json.loads(r.text)['data']['totalCount']
for d in data:
    tatal= tatal+d       
print('總共公司:',tatal)





